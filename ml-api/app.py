# ml-api/app.py
from fastapi import FastAPI, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import io
import time
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Malaria Detection API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ –∏–∏
IMG_SIZE = 224
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
logger.info(f"Using device: {device}")

val_tfms = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])


def build_model() -> nn.Module:
    """–§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –∏–∑ –≤–∞—à–µ–≥–æ –∫–æ–¥–∞"""
    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)
    for p in model.features.parameters():
        p.requires_grad = False
    model.classifier = nn.Sequential(
        nn.Dropout(0.3),
        nn.Linear(model.classifier[1].in_features, 2)
    )
    return model.to(device)


# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å (–∑–∞–º–µ–Ω–∏—Ç–µ –ø—É—Ç—å –Ω–∞ –≤–∞—à —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏)
try:
    model = build_model()
    # –ó–ê–ú–ï–ù–ò–¢–ï –≠–¢–£ –°–¢–†–û–ö–£ –ù–ê –ü–£–¢–¨ –ö –í–ê–®–ï–ô –°–û–•–†–ê–ù–ï–ù–ù–û–ô –ú–û–î–ï–õ–ò
    model.load_state_dict(torch.load('reports/best.pt', map_location=device))
    model.eval()
    logger.info("‚úÖ Model loaded successfully")
except Exception as e:
    logger.error(f"‚ùå Error loading model: {e}")
    model = None


def predict(image_data: bytes) -> dict:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–µ–≥–æ –∫–æ–¥–∞"""
    if model is None:
        return {"diagnosis": "error", "confidence": 0.0, "error": "Model not loaded"}

    try:
        start_time = time.time()

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = Image.open(io.BytesIO(image_data)).convert('RGB')
        image_tensor = val_tfms(image).unsqueeze(0).to(device)

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–∏–∑ –≤–∞—à–µ–≥–æ –∫–æ–¥–∞)
        with torch.no_grad():
            output = model(image_tensor)
            probability = torch.softmax(output, dim=1)[0][1].item()

        processing_time = time.time() - start_time

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏–∞–≥–Ω–æ–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ä–æ–≥–∞ 0.5
        diagnosis = "parasitized" if probability > 0.5 else "uninfected"

        return {
            "diagnosis": diagnosis,
            "confidence": probability,
            "processing_time": round(processing_time, 2),
            "model_used": "EfficientNet-B0"
        }

    except Exception as e:
        logger.error(f"Prediction error: {e}")
        return {
            "diagnosis": "error",
            "confidence": 0.0,
            "processing_time": 0.0,
            "error": str(e)
        }


@app.post("/analyze")
async def analyze_image(image: UploadFile = File(...)):
    """API endpoint –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
        if not image.content_type.startswith('image/'):
            return {"error": "File is not an image"}

        # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_data = await image.read()

        if len(image_data) == 0:
            return {"error": "Empty image file"}

        # –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        result = predict(image_data)

        return result

    except Exception as e:
        logger.error(f"API error: {e}")
        return {"error": f"Processing error: {str(e)}"}


@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–µ—Ä–∞"""
    status = "healthy" if model is not None else "model_not_loaded"
    return {
        "status": status,
        "service": "malaria-ml-api",
        "device": str(device),
        "model_loaded": model is not None
    }


@app.get("/model-info")
async def model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    if model is None:
        return {"error": "Model not loaded"}

    total_params = sum(p.numel() for p in model.parameters())
    return {
        "model_name": "EfficientNet-B0",
        "total_parameters": total_params,
        "input_size": IMG_SIZE,
        "device": str(device)
    }


if __name__ == "__main__":
    logger.info("üöÄ Starting ML API server on http://localhost:8000")
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")